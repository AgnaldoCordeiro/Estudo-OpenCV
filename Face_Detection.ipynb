{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-29T19:24:58.363820Z",
          "start_time": "2023-03-29T19:24:57.759798Z"
        },
        "id": "s5i1gwPIezav"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import dlib\n",
        "import face_recognition\n",
        "\n",
        "\n",
        "# Base de dados de imagens (exemplo com 2 imagens)\n",
        "base_de_dados = [\n",
        "    cv2.imread('myllena.jpg'), \n",
        " #   cv2.imread('agnaldo.jpg'), \n",
        "]\n",
        "\n",
        "\n",
        "# Caminho para o diretório com as imagens das pessoas autorizadas\n",
        "diretorio_base = './base/'\n",
        "\n",
        "# Inicialize o detector de faces do dlib\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# Inicialize o modelo de pontos de referência faciais do dlib\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Baixe o modelo apropriado\n",
        "\n",
        "# Carregue as imagens das pessoas autorizadas\n",
        "imagens_autorizadas = {}\n",
        "for filename in os.listdir(diretorio_base):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        nome_pessoa = os.path.splitext(filename)[0]\n",
        "        img = cv2.imread(os.path.join(diretorio_base, filename))\n",
        "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_encoding = face_recognition.face_encodings(rgb_img)\n",
        "        if img_encoding:\n",
        "            imagens_autorizadas[nome_pessoa] = img_encoding[0]\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a imagem: {filename}\")\n",
        "\n",
        "def verificar_acesso(imagem_detectada):\n",
        "    acesso_autorizado = False\n",
        "    nome_pessoa_autorizada = None\n",
        "\n",
        "    # Encontre os rostos na imagem da pessoa detectada\n",
        "    face_locations = face_recognition.face_locations(imagem_detectada)\n",
        "\n",
        "    if face_locations:\n",
        "        for face_location in face_locations:\n",
        "            # Recorte a imagem do rosto\n",
        "            top, right, bottom, left = face_location\n",
        "            face_image = imagem_detectada[top:bottom, left:right]\n",
        "\n",
        "            # Converta a imagem do rosto para o formato RGB\n",
        "            face_image_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Codifique o rosto\n",
        "            imagem_codificada = face_recognition.face_encodings(face_image_rgb)\n",
        "\n",
        "            if imagem_codificada:\n",
        "                for nome, encoding in imagens_autorizadas.items():\n",
        "                    result = face_recognition.compare_faces([encoding], imagem_codificada[0])\n",
        "                    if result[0]:\n",
        "                        acesso_autorizado = True\n",
        "                        nome_pessoa_autorizada = nome\n",
        "                        break\n",
        "\n",
        "            if acesso_autorizado:\n",
        "                break\n",
        "\n",
        "    return acesso_autorizado, nome_pessoa_autorizada\n",
        "\n",
        "\n",
        "\n",
        "# ========================-Downloading Assets-========================\n",
        "def download_and_unzip(url, save_path):\n",
        "    print(f\"Downloading and extracting assests....\", end=\"\")\n",
        "\n",
        "    # Downloading zip file using urllib package.\n",
        "    urlretrieve(url, save_path)\n",
        "\n",
        "    try:\n",
        "        # Extracting zip file using the zipfile package.\n",
        "        with ZipFile(save_path) as z:\n",
        "            # Extract ZIP file contents in the same directory.\n",
        "            z.extractall(os.path.split(save_path)[0])\n",
        "\n",
        "        print(\"Done\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nInvalid file.\", e)\n",
        "\n",
        "\n",
        "URL = r\"https://www.dropbox.com/s/efitgt363ada95a/opencv_bootcamp_assets_12.zip?dl=1\"\n",
        "\n",
        "asset_zip_path = os.path.join(os.getcwd(), f\"opencv_bootcamp_assets_12.zip\")\n",
        "\n",
        "# Download if assest ZIP does not exists.\n",
        "if not os.path.exists(asset_zip_path):\n",
        "    download_and_unzip(URL, asset_zip_path)\n",
        "# ====================================================================\n",
        "\n",
        "camera = \"https://192.168.15.157:8080/video\"\n",
        "\"\"\" s = 0\n",
        "if len(sys.argv) > 1:\n",
        "    s = sys.argv[1] \"\"\"\n",
        "\n",
        "source = cv2.VideoCapture(camera)\n",
        "\n",
        "win_name = \"Camera Preview\"\n",
        "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL) \n",
        "\n",
        "\n",
        "\n",
        "# Tente abrir a câmera virtual do OBS\n",
        "source = cv2.VideoCapture(camera)\n",
        "\n",
        "\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
        "# Model parameters\n",
        "in_width = 300\n",
        "in_height = 300\n",
        "mean = [104, 117, 123]\n",
        "conf_threshold = 0.7\n",
        "\n",
        "while cv2.waitKey(1) != 27:\n",
        "    has_frame, frame = source.read()\n",
        "    if not has_frame:\n",
        "        break\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    frame_height = frame.shape[0]\n",
        "    frame_width = frame.shape[1]\n",
        "\n",
        "    # Create a 4D blob from a frame.\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (in_width, in_height), mean, swapRB=False, crop=False)\n",
        "    # Run a model\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > conf_threshold:\n",
        "            x_left_bottom = int(detections[0, 0, i, 3] * frame_width)\n",
        "            y_left_bottom = int(detections[0, 0, i, 4] * frame_height)\n",
        "            x_right_top = int(detections[0, 0, i, 5] * frame_width)\n",
        "            y_right_top = int(detections[0, 0, i, 6] * frame_height)\n",
        "\n",
        "            # Verifique o acesso com base na imagem detectada\n",
        "            imagem_pessoa = frame[y_left_bottom:y_right_top, x_left_bottom:x_right_top]\n",
        "            acesso_autorizado = verificar_acesso(imagem_pessoa)\n",
        "            \n",
        "           \n",
        "\n",
        "            if acesso_autorizado:\n",
        "                cv2.rectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (0, 255, 0))\n",
        "                label = \"Acesso autorizado\"\n",
        "            else:\n",
        "                cv2.rectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (0, 0, 255))\n",
        "                label = \"Acesso não autorizado\"\n",
        "\n",
        "            # Desenhe a mensagem na imagem\n",
        "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "            cv2.rectangle(\n",
        "                frame,\n",
        "                (x_left_bottom, y_left_bottom - label_size[1]),\n",
        "                (x_left_bottom + label_size[0], y_left_bottom + base_line),\n",
        "                (255, 255, 255),\n",
        "                cv2.FILLED,\n",
        "            )\n",
        "            cv2.putText(frame, label, (x_left_bottom, y_left_bottom), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    label = \"Inference time: %.2f ms\" % (t * 1000.0 / cv2.getTickFrequency())\n",
        "    cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
        "    cv2.imshow(win_name, frame)\n",
        "\n",
        "source.release()\n",
        "cv2.destroyWindow(win_name)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "160px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
