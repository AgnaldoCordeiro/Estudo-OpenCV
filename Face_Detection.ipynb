{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-29T19:24:58.363820Z",
          "start_time": "2023-03-29T19:24:57.759798Z"
        },
        "id": "s5i1gwPIezav"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "verificar_acesso() takes 1 positional argument but 5 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Wordspace\\OpenCV\\Face_Detection.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m   imagem_pessoa \u001b[39m=\u001b[39m frame[y_left_bottom:y_right_top, x_left_bottom:x_right_top]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m \u001b[39m#  acesso_autorizado = verificar_acesso(imagem_pessoa)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m   \u001b[39m#imagem_pessoa = frame[y_left_bottom:y_right_top, x_left_bottom:x_right_top]\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m   acesso_autorizado \u001b[39m=\u001b[39m verificar_acesso(imagem_pessoa, x_left_bottom, y_left_bottom, x_right_top, y_right_top)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m   \u001b[39mif\u001b[39;00m acesso_autorizado:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Wordspace/OpenCV/Face_Detection.ipynb#W0sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m       cv2\u001b[39m.\u001b[39mrectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m))\n",
            "\u001b[1;31mTypeError\u001b[0m: verificar_acesso() takes 1 positional argument but 5 were given"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import dlib\n",
        "\n",
        "\n",
        "# Base de dados de imagens (exemplo com 2 imagens)\n",
        "base_de_dados = [\n",
        "    cv2.imread('myllena.jpg'), \n",
        " #   cv2.imread('agnaldo.jpg'), \n",
        "]\n",
        "\n",
        "\n",
        "# Caminho para o diretório com as imagens das pessoas autorizadas\n",
        "diretorio_base = './base/'\n",
        "\n",
        "# Inicialize o detector de faces do dlib\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# Inicialize o modelo de pontos de referência faciais do dlib\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Baixe o modelo apropriado\n",
        "\n",
        "# Carregue as imagens das pessoas autorizadas\n",
        "imagens_autorizadas = []\n",
        "for filename in os.listdir(diretorio_base):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        img = cv2.imread(os.path.join(diretorio_base, filename))\n",
        "        if img is not None:\n",
        "            imagens_autorizadas.append(img)\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a imagem: {filename}\")\n",
        "\n",
        "            \n",
        "\n",
        "def verificar_acesso(imagem_detectada):    \n",
        "    # Verifique se a imagem detectada não está vazia\n",
        "    if imagem_detectada is None:\n",
        "        return False\n",
        "  \n",
        "    # Verifique se as coordenadas do retângulo estão dentro dos limites da imagem\n",
        "    if (x_left_bottom < 0 or y_left_bottom < 0 or x_right_top >= imagem_detectada.shape[1] or y_right_top >= imagem_detectada.shape[0]):\n",
        "        return False\n",
        "\n",
        "    # Converta a região do retângulo para escala de cinza\n",
        "    imagem_roi = imagem_detectada[y_left_bottom:y_right_top, x_left_bottom:x_right_top]\n",
        "    imagem_gray = cv2.cvtColor(imagem_roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detecte as faces na região da imagem em escala de cinza\n",
        "    faces = detector(imagem_gray)\n",
        "   \n",
        "\n",
        "    for face in faces:\n",
        "        # Obtenha os pontos de referência faciais\n",
        "        landmarks = np.array(predictor(imagem_gray, face))\n",
        "\n",
        "        # Verifique se a imagem da face detectada corresponde a alguma das imagens autorizadas\n",
        "        for img_autorizada in imagens_autorizadas:\n",
        "            # Converta a imagem autorizada para escala de cinza\n",
        "            img_autorizada_gray = cv2.cvtColor(img_autorizada, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Detecte as faces na imagem autorizada\n",
        "            faces_autorizadas = detector(img_autorizada_gray)\n",
        "            \n",
        "            for face_autorizada in faces_autorizadas:\n",
        "                # Obtenha os pontos de referência faciais da imagem autorizada\n",
        "                landmarks_autorizados = np.array(predictor(img_autorizada_gray, face_autorizada))\n",
        "                \n",
        "                # Compare os pontos de referência faciais das duas faces\n",
        "                diff = np.linalg.norm(landmarks - landmarks_autorizados)\n",
        "              \n",
        "                # Defina um limite para considerar como correspondência (ajuste conforme necessário)\n",
        "                limite_correspondencia = 25.0\n",
        "                \n",
        "                if diff < limite_correspondencia:\n",
        "                    return True  # Se houver correspondência, retorna True\n",
        "\n",
        "    return False  # Se não houver correspondência com nenhuma imagem autorizada, retorna False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ========================-Downloading Assets-========================\n",
        "def download_and_unzip(url, save_path):\n",
        "    print(f\"Downloading and extracting assests....\", end=\"\")\n",
        "\n",
        "    # Downloading zip file using urllib package.\n",
        "    urlretrieve(url, save_path)\n",
        "\n",
        "    try:\n",
        "        # Extracting zip file using the zipfile package.\n",
        "        with ZipFile(save_path) as z:\n",
        "            # Extract ZIP file contents in the same directory.\n",
        "            z.extractall(os.path.split(save_path)[0])\n",
        "\n",
        "        print(\"Done\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nInvalid file.\", e)\n",
        "\n",
        "\n",
        "URL = r\"https://www.dropbox.com/s/efitgt363ada95a/opencv_bootcamp_assets_12.zip?dl=1\"\n",
        "\n",
        "asset_zip_path = os.path.join(os.getcwd(), f\"opencv_bootcamp_assets_12.zip\")\n",
        "\n",
        "# Download if assest ZIP does not exists.\n",
        "if not os.path.exists(asset_zip_path):\n",
        "    download_and_unzip(URL, asset_zip_path)\n",
        "# ====================================================================\n",
        "\n",
        "camera = \"https://192.168.15.157:8080/video\"\n",
        "\"\"\" s = 0\n",
        "if len(sys.argv) > 1:\n",
        "    s = sys.argv[1] \"\"\"\n",
        "\n",
        "source = cv2.VideoCapture(camera)\n",
        "\n",
        "win_name = \"Camera Preview\"\n",
        "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL) \n",
        "\n",
        "\n",
        "\n",
        "# Tente abrir a câmera virtual do OBS\n",
        "source = cv2.VideoCapture(camera)\n",
        "\n",
        "\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
        "# Model parameters\n",
        "in_width = 300\n",
        "in_height = 300\n",
        "mean = [104, 117, 123]\n",
        "conf_threshold = 0.7\n",
        "\n",
        "while cv2.waitKey(1) != 27:\n",
        "    has_frame, frame = source.read()\n",
        "    if not has_frame:\n",
        "        break\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    frame_height = frame.shape[0]\n",
        "    frame_width = frame.shape[1]\n",
        "\n",
        "    # Create a 4D blob from a frame.\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (in_width, in_height), mean, swapRB=False, crop=False)\n",
        "    # Run a model\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > conf_threshold:\n",
        "            x_left_bottom = int(detections[0, 0, i, 3] * frame_width)\n",
        "            y_left_bottom = int(detections[0, 0, i, 4] * frame_height)\n",
        "            x_right_top = int(detections[0, 0, i, 5] * frame_width)\n",
        "            y_right_top = int(detections[0, 0, i, 6] * frame_height)\n",
        "\n",
        "            # Verifique o acesso com base na imagem detectada\n",
        "            imagem_pessoa = frame[y_left_bottom:y_right_top, x_left_bottom:x_right_top]\n",
        "            acesso_autorizado = verificar_acesso(imagem_pessoa)\n",
        "            \n",
        "           \n",
        "\n",
        "            if acesso_autorizado:\n",
        "                cv2.rectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (0, 255, 0))\n",
        "                label = \"Acesso autorizado\"\n",
        "            else:\n",
        "                cv2.rectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (0, 0, 255))\n",
        "                label = \"Acesso não autorizado\"\n",
        "\n",
        "            # Desenhe a mensagem na imagem\n",
        "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "            cv2.rectangle(\n",
        "                frame,\n",
        "                (x_left_bottom, y_left_bottom - label_size[1]),\n",
        "                (x_left_bottom + label_size[0], y_left_bottom + base_line),\n",
        "                (255, 255, 255),\n",
        "                cv2.FILLED,\n",
        "            )\n",
        "            cv2.putText(frame, label, (x_left_bottom, y_left_bottom), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    label = \"Inference time: %.2f ms\" % (t * 1000.0 / cv2.getTickFrequency())\n",
        "    cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
        "    cv2.imshow(win_name, frame)\n",
        "\n",
        "source.release()\n",
        "cv2.destroyWindow(win_name)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "160px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
